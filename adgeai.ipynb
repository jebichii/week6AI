{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c79d7f-d648-4cda-81e7-bbb02600a643",
   "metadata": {
    "id": "16c79d7f-d648-4cda-81e7-bbb02600a643"
   },
   "source": [
    "# ğŸ” Edge AI Prototype: Recyclable Item Classification with TensorFlow Lite\n",
    "\n",
    "## ğŸ¯ Objective\n",
    "- Train a lightweight CNN model to classify recyclable items.\n",
    "- Convert to TensorFlow Lite for edge deployment.\n",
    "- Test on sample images and report performance.\n",
    "- Highlight Edge AI advantages in real-time applications.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1533f6-0a89-4728-bf98-e9fe7ad4b4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "# Install essential libraries (Colab typically has these pre-installed)\n",
    "!pip install tensorflow numpy matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5e0e058-95ff-4169-b992-f2e8211e5386",
   "metadata": {
    "id": "a5e0e058-95ff-4169-b992-f2e8211e5386"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f40b9cbb-6ed5-4a1a-9370-13ad32d299bd",
   "metadata": {
    "id": "f40b9cbb-6ed5-4a1a-9370-13ad32d299bd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Filter only 'bottle' class (label 9) to simulate recyclable item classification\n",
    "x_train = x_train[y_train.flatten() == 9]\n",
    "y_train = y_train[y_train.flatten() == 9]\n",
    "\n",
    "x_test = x_test[y_test.flatten() == 9]\n",
    "y_test = y_test[y_test.flatten() == 9]\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7f884b7-c2dd-42b7-83b8-6c07437fcfeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7f884b7-c2dd-42b7-83b8-6c07437fcfeb",
    "outputId": "3de1e5b1-e2b7-4342-f204-e1dd9103c886"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9732 - loss: 0.0460 - val_accuracy: 1.0000 - val_loss: 1.5053e-06\n",
      "Epoch 2/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 6.9239e-07 - val_accuracy: 1.0000 - val_loss: 1.3673e-06\n",
      "Epoch 3/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.3286e-07 - val_accuracy: 1.0000 - val_loss: 1.2089e-06\n",
      "Epoch 4/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.7542e-07 - val_accuracy: 1.0000 - val_loss: 1.0443e-06\n",
      "Epoch 5/5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 8.9120e-07 - val_accuracy: 1.0000 - val_loss: 8.9900e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ac1281da190>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define lightweight CNN model architecture for Edge deployment\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # binary classification\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, np.ones(len(x_train)), epochs=5, validation_data=(x_test, np.ones(len(x_test))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "863aa928-8cd0-4019-a53c-2b7361c499d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "863aa928-8cd0-4019-a53c-2b7361c499d3",
    "outputId": "16b52b01-bdf0-489a-f555-b79cd1a4781e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpxae43x0b'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='keras_tensor_8')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  134970157380624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134970157383312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134970157373904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134970157378512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134970157380816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134970157379664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "# Convert trained model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model\n",
    "with open('recyclable_classifier.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "687c0de1-8dc5-4b1e-bc5e-00c7453eb08d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "687c0de1-8dc5-4b1e-bc5e-00c7453eb08d",
    "outputId": "83135d2a-6308-4a0f-d5f5-e26f1884fcde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted recyclable: [ True]\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path='recyclable_classifier.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input/output tensors info\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Run inference on a sample image\n",
    "test_image = x_test[0].reshape(1, 32, 32, 3).astype(np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "interpreter.invoke()\n",
    "prediction = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(\"Predicted recyclable:\", prediction[0] > 0.5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "977e200c-eaf8-4623-b2ec-c0b0901109ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "977e200c-eaf8-4623-b2ec-c0b0901109ce",
    "outputId": "544bb3d7-f867-4b23-d719-658e926d4aab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.8169e-07\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "loss, acc = model.evaluate(x_test, np.ones(len(x_test)))\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VgqAg1HZ0hGe",
   "metadata": {
    "id": "VgqAg1HZ0hGe"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "j5pDxaNw0k0y",
   "metadata": {
    "id": "j5pDxaNw0k0y"
   },
   "source": [
    "## ğŸ’¡ Why Edge AI Matters\n",
    "\n",
    "- âš¡ **Low Latency**: On-device processing avoids cloud delays.\n",
    "- ğŸ” **Privacy**: Data stays local, reducing exposure risks.\n",
    "- ğŸ“¡ **Offline Functionality**: Ideal for areas without reliable connectivity.\n",
    "- ğŸ”‹ **Energy Efficiency**: TensorFlow Lite models require minimal compute power.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
